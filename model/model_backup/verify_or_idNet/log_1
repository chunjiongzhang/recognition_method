opt = Namespace(PCB=False, alpha=1.0, batchsize=48, color_jitter=False, data_dir='data/market/pytorch', erasing_p=0.5, gpu_ids='0', lr=0.1, name='sggnn', net_loss_model=2, save_model_name='1', train_all=True, use_dense=True)
net_loss_model = 2
save_model_name = 1
[Resize(size=(256, 128), interpolation=PIL.Image.BICUBIC), Pad(padding=10, fill=0, padding_mode=constant), RandomCrop(size=(256, 128), padding=0), RandomHorizontalFlip(p=0.5), ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), <random_erasing.RandomErasing object at 0x7f25bd411048>]
7.152557373046875e-07
model_siamese structure
Epoch 0/99
----------
train Loss_id: 0.1470 Loss_verif: 0.0144  Acc_id: 0.3393 Verif_Acc: 0.5171 
Epoch 1/99
----------
train Loss_id: 0.0480 Loss_verif: 0.0144  Acc_id: 0.7057 Verif_Acc: 0.5148 
Epoch 2/99
----------
train Loss_id: 0.0287 Loss_verif: 0.0144  Acc_id: 0.8157 Verif_Acc: 0.5092 
Epoch 3/99
----------
train Loss_id: 0.0214 Loss_verif: 0.0144  Acc_id: 0.8613 Verif_Acc: 0.4974 
Epoch 4/99
----------
train Loss_id: 0.0164 Loss_verif: 0.0144  Acc_id: 0.8954 Verif_Acc: 0.5077 
Epoch 5/99
----------
train Loss_id: 0.0141 Loss_verif: 0.0144  Acc_id: 0.9078 Verif_Acc: 0.5018 
Epoch 6/99
----------
train Loss_id: 0.0127 Loss_verif: 0.0144  Acc_id: 0.9164 Verif_Acc: 0.5053 
Epoch 7/99
----------
train Loss_id: 0.0112 Loss_verif: 0.0144  Acc_id: 0.9257 Verif_Acc: 0.4971 
Epoch 8/99
----------
train Loss_id: 0.0102 Loss_verif: 0.0144  Acc_id: 0.9338 Verif_Acc: 0.4982 
Epoch 9/99
----------
train Loss_id: 0.0104 Loss_verif: 0.0144  Acc_id: 0.9337 Verif_Acc: 0.5036 
Epoch 10/99
----------
train Loss_id: 0.0098 Loss_verif: 0.0144  Acc_id: 0.9370 Verif_Acc: 0.5065 
Epoch 11/99
----------
train Loss_id: 0.0086 Loss_verif: 0.0144  Acc_id: 0.9435 Verif_Acc: 0.5057 
Epoch 12/99
----------
train Loss_id: 0.0078 Loss_verif: 0.0144  Acc_id: 0.9488 Verif_Acc: 0.5036 
Epoch 13/99
----------
train Loss_id: 0.0081 Loss_verif: 0.0144  Acc_id: 0.9492 Verif_Acc: 0.5039 
Epoch 14/99
----------
train Loss_id: 0.0073 Loss_verif: 0.0144  Acc_id: 0.9535 Verif_Acc: 0.5051 
Epoch 15/99
----------
train Loss_id: 0.0066 Loss_verif: 0.0144  Acc_id: 0.9579 Verif_Acc: 0.4994 
Epoch 16/99
----------
train Loss_id: 0.0069 Loss_verif: 0.0144  Acc_id: 0.9565 Verif_Acc: 0.4974 
Epoch 17/99
----------
train Loss_id: 0.0068 Loss_verif: 0.0144  Acc_id: 0.9562 Verif_Acc: 0.4998 
Epoch 18/99
----------
train Loss_id: 0.0068 Loss_verif: 0.0144  Acc_id: 0.9571 Verif_Acc: 0.5033 
Epoch 19/99
----------
train Loss_id: 0.0063 Loss_verif: 0.0144  Acc_id: 0.9612 Verif_Acc: 0.4994 
Epoch 20/99
----------
train Loss_id: 0.0059 Loss_verif: 0.0144  Acc_id: 0.9635 Verif_Acc: 0.5026 
Epoch 21/99
----------
train Loss_id: 0.0062 Loss_verif: 0.0144  Acc_id: 0.9614 Verif_Acc: 0.5087 
Epoch 22/99
----------
train Loss_id: 0.0060 Loss_verif: 0.0144  Acc_id: 0.9609 Verif_Acc: 0.5074 
Epoch 23/99
----------
train Loss_id: 0.0059 Loss_verif: 0.0144  Acc_id: 0.9627 Verif_Acc: 0.5019 
Epoch 24/99
----------
train Loss_id: 0.0061 Loss_verif: 0.0144  Acc_id: 0.9608 Verif_Acc: 0.4954 
Epoch 25/99
----------
train Loss_id: 0.0055 Loss_verif: 0.0144  Acc_id: 0.9664 Verif_Acc: 0.4979 
Epoch 26/99
----------
train Loss_id: 0.0061 Loss_verif: 0.0144  Acc_id: 0.9633 Verif_Acc: 0.4981 
Epoch 27/99
----------
train Loss_id: 0.0065 Loss_verif: 0.0144  Acc_id: 0.9597 Verif_Acc: 0.4929 
Epoch 28/99
----------
train Loss_id: 0.0054 Loss_verif: 0.0144  Acc_id: 0.9657 Verif_Acc: 0.4993 
Epoch 29/99
----------
train Loss_id: 0.0048 Loss_verif: 0.0144  Acc_id: 0.9722 Verif_Acc: 0.4979 
Epoch 30/99
----------
train Loss_id: 0.0027 Loss_verif: 0.0144  Acc_id: 0.9850 Verif_Acc: 0.5011 
Epoch 31/99
----------
train Loss_id: 0.0016 Loss_verif: 0.0144  Acc_id: 0.9926 Verif_Acc: 0.5057 
Epoch 32/99
----------
train Loss_id: 0.0014 Loss_verif: 0.0144  Acc_id: 0.9938 Verif_Acc: 0.4988 
Epoch 33/99
----------
train Loss_id: 0.0013 Loss_verif: 0.0144  Acc_id: 0.9943 Verif_Acc: 0.4956 
Epoch 34/99
----------
train Loss_id: 0.0012 Loss_verif: 0.0144  Acc_id: 0.9950 Verif_Acc: 0.4967 
Epoch 35/99
----------
train Loss_id: 0.0012 Loss_verif: 0.0144  Acc_id: 0.9946 Verif_Acc: 0.5031 
Epoch 36/99
----------
train Loss_id: 0.0011 Loss_verif: 0.0144  Acc_id: 0.9954 Verif_Acc: 0.4938 
Epoch 37/99
----------
train Loss_id: 0.0011 Loss_verif: 0.0144  Acc_id: 0.9962 Verif_Acc: 0.4940 
Epoch 38/99
----------
train Loss_id: 0.0011 Loss_verif: 0.0144  Acc_id: 0.9957 Verif_Acc: 0.4907 
Epoch 39/99
----------
train Loss_id: 0.0010 Loss_verif: 0.0144  Acc_id: 0.9962 Verif_Acc: 0.4934 
Epoch 40/99
----------
train Loss_id: 0.0010 Loss_verif: 0.0144  Acc_id: 0.9966 Verif_Acc: 0.4983 
Epoch 41/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9967 Verif_Acc: 0.5045 
Epoch 42/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9974 Verif_Acc: 0.5019 
Epoch 43/99
----------
train Loss_id: 0.0010 Loss_verif: 0.0144  Acc_id: 0.9967 Verif_Acc: 0.5030 
Epoch 44/99
----------
train Loss_id: 0.0010 Loss_verif: 0.0144  Acc_id: 0.9967 Verif_Acc: 0.5004 
Epoch 45/99
----------
train Loss_id: 0.0010 Loss_verif: 0.0144  Acc_id: 0.9971 Verif_Acc: 0.5006 
Epoch 46/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9971 Verif_Acc: 0.5008 
Epoch 47/99
----------
train Loss_id: 0.0010 Loss_verif: 0.0144  Acc_id: 0.9969 Verif_Acc: 0.4959 
Epoch 48/99
----------
train Loss_id: 0.0010 Loss_verif: 0.0144  Acc_id: 0.9972 Verif_Acc: 0.5064 
Epoch 49/99
----------
train Loss_id: 0.0010 Loss_verif: 0.0144  Acc_id: 0.9973 Verif_Acc: 0.4939 
Epoch 50/99
----------
train Loss_id: 0.0008 Loss_verif: 0.0144  Acc_id: 0.9984 Verif_Acc: 0.5030 
Epoch 51/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9979 Verif_Acc: 0.5013 
Epoch 52/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9979 Verif_Acc: 0.4919 
Epoch 53/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9976 Verif_Acc: 0.5002 
Epoch 54/99
----------
train Loss_id: 0.0010 Loss_verif: 0.0144  Acc_id: 0.9968 Verif_Acc: 0.4962 
Epoch 55/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9981 Verif_Acc: 0.5019 
Epoch 56/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9981 Verif_Acc: 0.4919 
Epoch 57/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9982 Verif_Acc: 0.4930 
Epoch 58/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9980 Verif_Acc: 0.4998 
Epoch 59/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9985 Verif_Acc: 0.5015 
Epoch 60/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9982 Verif_Acc: 0.4975 
Epoch 61/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9986 Verif_Acc: 0.5010 
Epoch 62/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9979 Verif_Acc: 0.4941 
Epoch 63/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9979 Verif_Acc: 0.4987 
Epoch 64/99
----------
train Loss_id: 0.0008 Loss_verif: 0.0144  Acc_id: 0.9986 Verif_Acc: 0.5069 
Epoch 65/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9978 Verif_Acc: 0.4976 
Epoch 66/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9982 Verif_Acc: 0.4954 
Epoch 67/99
----------
train Loss_id: 0.0010 Loss_verif: 0.0144  Acc_id: 0.9973 Verif_Acc: 0.5006 
Epoch 68/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9981 Verif_Acc: 0.4972 
Epoch 69/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9975 Verif_Acc: 0.5039 
Epoch 70/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9983 Verif_Acc: 0.4943 
Epoch 71/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9980 Verif_Acc: 0.4961 
Epoch 72/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9979 Verif_Acc: 0.4933 
Epoch 73/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9984 Verif_Acc: 0.4929 
Epoch 74/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9980 Verif_Acc: 0.4995 
Epoch 75/99
----------
train Loss_id: 0.0008 Loss_verif: 0.0144  Acc_id: 0.9985 Verif_Acc: 0.5050 
Epoch 76/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9981 Verif_Acc: 0.5020 
Epoch 77/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9982 Verif_Acc: 0.4942 
Epoch 78/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9982 Verif_Acc: 0.4969 
Epoch 79/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9978 Verif_Acc: 0.4978 
Epoch 80/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9985 Verif_Acc: 0.5005 
Epoch 81/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9983 Verif_Acc: 0.4999 
Epoch 82/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9980 Verif_Acc: 0.5046 
Epoch 83/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9978 Verif_Acc: 0.4924 
Epoch 84/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9983 Verif_Acc: 0.5005 
Epoch 85/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9984 Verif_Acc: 0.5030 
Epoch 86/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9982 Verif_Acc: 0.4936 
Epoch 87/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9984 Verif_Acc: 0.4972 
Epoch 88/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9983 Verif_Acc: 0.5039 
Epoch 89/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9984 Verif_Acc: 0.4922 
Epoch 90/99
----------
train Loss_id: 0.0008 Loss_verif: 0.0144  Acc_id: 0.9986 Verif_Acc: 0.5002 
Epoch 91/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9985 Verif_Acc: 0.4922 
Epoch 92/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9985 Verif_Acc: 0.5069 
Epoch 93/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9983 Verif_Acc: 0.4968 
Epoch 94/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9983 Verif_Acc: 0.4973 
Epoch 95/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9981 Verif_Acc: 0.4964 
Epoch 96/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9983 Verif_Acc: 0.4956 
Epoch 97/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9983 Verif_Acc: 0.4878 
Epoch 98/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9980 Verif_Acc: 0.5022 
Epoch 99/99
----------
train Loss_id: 0.0009 Loss_verif: 0.0144  Acc_id: 0.9980 Verif_Acc: 0.5015 
best_epoch = 64     best_loss = 0.007644629978535575     best_acc = 0.7527493804213135
Training complete in 153m 43s
This is not an error. If you want to use low precision, i.e., fp16, please install the apex with cuda support (https://github.com/NVIDIA/apex) and update pytorch to 1.0
opt = Namespace(PCB=False, batchsize=48, fp16=False, gpu_ids='0', name='sggnn', test_dir='data/market/pytorch', use_dense=True, which_epoch='best_siamese')
opt.gpu_ids = 0
opt.which_epoch = best_siamese
opt.test_dir = data/market/pytorch
opt.name = sggnn
opt.batchsize = 48
opt.use_dense = True
opt.PCB = False
opt.fp16 = False
-------test-----------
load easy pretrained model: ./model/sggnn/net_best_siamese.pth
torch.Size([3368, 512])
i =    0    CMC_tmp[0] = 1  real-time rank1 = 1.0000  avg rank1 = 1.0000
i =  100    CMC_tmp[0] = 0  real-time rank1 = 0.7822  avg rank1 = 0.7921
i =  200    CMC_tmp[0] = 1  real-time rank1 = 0.8020  avg rank1 = 0.8010
i =  300    CMC_tmp[0] = 1  real-time rank1 = 0.7723  avg rank1 = 0.7940
i =  400    CMC_tmp[0] = 1  real-time rank1 = 0.7525  avg rank1 = 0.7855
i =  500    CMC_tmp[0] = 1  real-time rank1 = 0.9208  avg rank1 = 0.8144
i =  600    CMC_tmp[0] = 1  real-time rank1 = 0.8713  avg rank1 = 0.8253
i =  700    CMC_tmp[0] = 1  real-time rank1 = 0.9406  avg rank1 = 0.8431
i =  800    CMC_tmp[0] = 1  real-time rank1 = 0.9307  avg rank1 = 0.8552
i =  900    CMC_tmp[0] = 0  real-time rank1 = 0.9010  avg rank1 = 0.8613
i = 1000    CMC_tmp[0] = 1  real-time rank1 = 0.8218  avg rank1 = 0.8581
i = 1100    CMC_tmp[0] = 1  real-time rank1 = 0.9109  avg rank1 = 0.8638
i = 1200    CMC_tmp[0] = 1  real-time rank1 = 0.8713  avg rank1 = 0.8651
i = 1300    CMC_tmp[0] = 1  real-time rank1 = 0.9109  avg rank1 = 0.8693
i = 1400    CMC_tmp[0] = 1  real-time rank1 = 0.9010  avg rank1 = 0.8722
i = 1500    CMC_tmp[0] = 1  real-time rank1 = 0.9505  avg rank1 = 0.8781
i = 1600    CMC_tmp[0] = 1  real-time rank1 = 0.8713  avg rank1 = 0.8782
i = 1700    CMC_tmp[0] = 1  real-time rank1 = 0.9109  avg rank1 = 0.8807
i = 1800    CMC_tmp[0] = 1  real-time rank1 = 0.9406  avg rank1 = 0.8845
i = 1900    CMC_tmp[0] = 1  real-time rank1 = 0.8614  avg rank1 = 0.8837
i = 2000    CMC_tmp[0] = 1  real-time rank1 = 0.9406  avg rank1 = 0.8871
i = 2100    CMC_tmp[0] = 1  real-time rank1 = 0.9505  avg rank1 = 0.8905
i = 2200    CMC_tmp[0] = 1  real-time rank1 = 0.8812  avg rank1 = 0.8905
i = 2300    CMC_tmp[0] = 1  real-time rank1 = 0.9010  avg rank1 = 0.8914
i = 2400    CMC_tmp[0] = 1  real-time rank1 = 0.9109  avg rank1 = 0.8925
i = 2500    CMC_tmp[0] = 1  real-time rank1 = 0.9109  avg rank1 = 0.8936
i = 2600    CMC_tmp[0] = 1  real-time rank1 = 0.9109  avg rank1 = 0.8947
i = 2700    CMC_tmp[0] = 1  real-time rank1 = 0.9307  avg rank1 = 0.8963
i = 2800    CMC_tmp[0] = 0  real-time rank1 = 0.9208  avg rank1 = 0.8975
i = 2900    CMC_tmp[0] = 1  real-time rank1 = 0.9604  avg rank1 = 0.9000
i = 3000    CMC_tmp[0] = 1  real-time rank1 = 0.9505  avg rank1 = 0.9020
i = 3100    CMC_tmp[0] = 1  real-time rank1 = 0.9208  avg rank1 = 0.9029
i = 3200    CMC_tmp[0] = 1  real-time rank1 = 0.9406  avg rank1 = 0.9044
i = 3300    CMC_tmp[0] = 1  real-time rank1 = 0.9406  avg rank1 = 0.9058
i = 3367    CMC_tmp[0] = 1  real-time rank1 = 0.9412  avg rank1 = 0.9068
Rank@1:0.906770 Rank@5:0.972684 Rank@10:0.982779 mAP:0.763350
calculate initial distance
Reranking complete in 1m 9s
top1:0.932007 top5:0.964964 top10:0.974466 mAP:0.902233
This is not an error. If you want to use low precision, i.e., fp16, please install the apex with cuda support (https://github.com/NVIDIA/apex) and update pytorch to 1.0
opt = Namespace(PCB=False, batchsize=48, fp16=False, gpu_ids='0', name='sggnn', test_dir='data/market/pytorch', use_dense=True, which_epoch='last_siamese')
opt.gpu_ids = 0
opt.which_epoch = last_siamese
opt.test_dir = data/market/pytorch
opt.name = sggnn
opt.batchsize = 48
opt.use_dense = True
opt.PCB = False
opt.fp16 = False
-------test-----------
load easy pretrained model: ./model/sggnn/net_last_siamese.pth
torch.Size([3368, 512])
i =    0    CMC_tmp[0] = 1  real-time rank1 = 1.0000  avg rank1 = 1.0000
i =  100    CMC_tmp[0] = 0  real-time rank1 = 0.7822  avg rank1 = 0.7921
i =  200    CMC_tmp[0] = 1  real-time rank1 = 0.8020  avg rank1 = 0.8010
i =  300    CMC_tmp[0] = 1  real-time rank1 = 0.7723  avg rank1 = 0.7940
i =  400    CMC_tmp[0] = 1  real-time rank1 = 0.7525  avg rank1 = 0.7855
i =  500    CMC_tmp[0] = 1  real-time rank1 = 0.9208  avg rank1 = 0.8144
i =  600    CMC_tmp[0] = 1  real-time rank1 = 0.8713  avg rank1 = 0.8253
i =  700    CMC_tmp[0] = 1  real-time rank1 = 0.9406  avg rank1 = 0.8431
i =  800    CMC_tmp[0] = 1  real-time rank1 = 0.9307  avg rank1 = 0.8552
i =  900    CMC_tmp[0] = 0  real-time rank1 = 0.9010  avg rank1 = 0.8613
i = 1000    CMC_tmp[0] = 1  real-time rank1 = 0.8218  avg rank1 = 0.8581
i = 1100    CMC_tmp[0] = 1  real-time rank1 = 0.9109  avg rank1 = 0.8638
i = 1200    CMC_tmp[0] = 1  real-time rank1 = 0.8713  avg rank1 = 0.8651
i = 1300    CMC_tmp[0] = 1  real-time rank1 = 0.9109  avg rank1 = 0.8693
i = 1400    CMC_tmp[0] = 1  real-time rank1 = 0.9010  avg rank1 = 0.8722
i = 1500    CMC_tmp[0] = 1  real-time rank1 = 0.9505  avg rank1 = 0.8781
i = 1600    CMC_tmp[0] = 1  real-time rank1 = 0.8713  avg rank1 = 0.8782
i = 1700    CMC_tmp[0] = 1  real-time rank1 = 0.9109  avg rank1 = 0.8807
i = 1800    CMC_tmp[0] = 1  real-time rank1 = 0.9406  avg rank1 = 0.8845
i = 1900    CMC_tmp[0] = 1  real-time rank1 = 0.8614  avg rank1 = 0.8837
i = 2000    CMC_tmp[0] = 1  real-time rank1 = 0.9406  avg rank1 = 0.8871
i = 2100    CMC_tmp[0] = 1  real-time rank1 = 0.9505  avg rank1 = 0.8905
i = 2200    CMC_tmp[0] = 1  real-time rank1 = 0.8812  avg rank1 = 0.8905
i = 2300    CMC_tmp[0] = 1  real-time rank1 = 0.9010  avg rank1 = 0.8914
i = 2400    CMC_tmp[0] = 1  real-time rank1 = 0.9109  avg rank1 = 0.8925
i = 2500    CMC_tmp[0] = 1  real-time rank1 = 0.9109  avg rank1 = 0.8936
i = 2600    CMC_tmp[0] = 1  real-time rank1 = 0.9109  avg rank1 = 0.8947
i = 2700    CMC_tmp[0] = 1  real-time rank1 = 0.9307  avg rank1 = 0.8963
i = 2800    CMC_tmp[0] = 0  real-time rank1 = 0.9208  avg rank1 = 0.8975
i = 2900    CMC_tmp[0] = 1  real-time rank1 = 0.9604  avg rank1 = 0.9000
i = 3000    CMC_tmp[0] = 1  real-time rank1 = 0.9505  avg rank1 = 0.9020
i = 3100    CMC_tmp[0] = 1  real-time rank1 = 0.9208  avg rank1 = 0.9029
i = 3200    CMC_tmp[0] = 1  real-time rank1 = 0.9406  avg rank1 = 0.9044
i = 3300    CMC_tmp[0] = 1  real-time rank1 = 0.9406  avg rank1 = 0.9058
i = 3367    CMC_tmp[0] = 1  real-time rank1 = 0.9412  avg rank1 = 0.9068
Rank@1:0.906770 Rank@5:0.972684 Rank@10:0.982779 mAP:0.763350
calculate initial distance
Reranking complete in 1m 9s
top1:0.932007 top5:0.964964 top10:0.974466 mAP:0.902233
